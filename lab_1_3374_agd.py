# -*- coding: utf-8 -*-
"""LAB_1_3374_AGD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-CG70RpwK-vl5bqvbEnwDK2ZB1m8IqL9
"""

# Лабораторная работа 1 - анализ набора данных
# Группа 3374 - Гришина Анастасия Дмитриевна

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# настройка отображения графиков
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 10
sns.set_palette("husl")
sns.set_style("darkgrid")

# датасет о автомобилях
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"
column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']
df = pd.read_csv(url, delim_whitespace=True, names=column_names, na_values='?')

print(f"Размерность данных: {df.shape}")
print(f"Количество признаков: {len(df.columns)}")
print(f"Количество наблюдений: {len(df)}")

# информация о датасете
print("Auto MPG Dataset - характеристики автомобилей")
print("Источник UCI Repository | Реальные данные")
print("Признаки mpg, cylinders, displacement, horsepower, weight, acceleration, model_year, origin, car_name")
print("Целевая переменная mpg (миль на галлон)")

# начальные данные

# первые строки таблицы датасета
display(df.head(9))

# информация
df.info()

# Описание статистических данных
stats_summary = pd.DataFrame({
    'Среднее': df.select_dtypes(include=[np.number]).mean(),
    'Стандартное отклонение': df.select_dtypes(include=[np.number]).std(),
    'Медиана': df.select_dtypes(include=[np.number]).median(),
    'Минимум': df.select_dtypes(include=[np.number]).min(),
    'Максимум': df.select_dtypes(include=[np.number]).max(),
    'Количество пропусков': df.isnull().sum()
})
display(stats_summary.round(3))

# Анализ пропущенных данных
missing_count = df.isnull().sum()
missing_percent = (missing_count / len(df)) * 100
missing_df = pd.DataFrame({
    'Количество пропусков': missing_count,
    'Процент пропусков': missing_percent
})
missing_df = missing_df[missing_df['Количество пропусков'] > 0]

if missing_df.empty:
    print("Пропущенные значения отсутствуют")
else:
    display(missing_df.round(2))
    print("Варианты обработки пропусков")
    print("Замена средним значением для числовых признаков")
    print("Удаление строк с пропусками, если их мало")

# Графики распределений
numeric_cols = df.select_dtypes(include=[np.number]).columns
fig, axes = plt.subplots(3, 3, figsize=(15, 12))
axes = axes.ravel()

for i, col in enumerate(numeric_cols):
    if i < len(axes):
        sns.histplot(df[col], kde=True, ax=axes[i], bins=15, color='skyblue')
        axes[i].axvline(df[col].mean(), color='red', linestyle='--', label='Среднее')
        axes[i].axvline(df[col].median(), color='green', linestyle='--', label='Медиана')
        axes[i].set_title(f'Распределение {col}', fontweight='bold')
        axes[i].legend()

plt.tight_layout()
plt.show()

# График выбросов
fig, axes = plt.subplots(3, 3, figsize=(15, 12))
axes = axes.ravel()

for i, col in enumerate(numeric_cols):
    if i < len(axes):
        sns.boxplot(y=df[col], ax=axes[i], color='lightcoral')
        axes[i].set_title(f'Выбросы: {col}', fontweight='bold')

plt.tight_layout()
plt.show()

# Количественный анализ выбросов
def detect_outliers(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = series[(series < lower_bound) | (series > upper_bound)]
    return len(outliers), f"{(len(outliers)/len(series))*100:.1f}%"

outliers_info = []
for col in numeric_cols:
    count, percentage = detect_outliers(df[col])
    outliers_info.append({
        'Признак': col,
        'Выбросы': count,
        'Процент': percentage
    })

outliers_df = pd.DataFrame(outliers_info)
display(outliers_df)

high_outliers = outliers_df[outliers_df['Процент'].str.replace('%', '').astype(float) > 5]
if not high_outliers.empty:
    # Признаки с > 5%
    print("Признаки с большим количеством выбросов:")
    for _, row in high_outliers.iterrows():
        print(f"  • {row['Признак']}: {row['Выбросы']} ({row['Процент']})")

# Корреляционный анализ
# Матрица корреляций
corr_matrix = df.select_dtypes(include=[np.number]).corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, square=True, fmt='.2f', cbar_kws={"shrink": .8})
plt.title('Матрица корреляций между признаками', fontsize=14, pad=20)
plt.tight_layout()
plt.show()

# Анализ сильных корреляций
# Сильная корреляция, где |r| > 0.7
print("Сильная корреляция")
strong_correlations = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        corr = corr_matrix.iloc[i, j]
        if abs(corr) > 0.7:
            strong_correlations.append((corr_matrix.columns[i], corr_matrix.columns[j], corr))

if strong_correlations:
    for col1, col2, corr in sorted(strong_correlations, key=lambda x: abs(x[2]), reverse=True):
        direction = "положительная" if corr > 0 else "отрицательная"
        print(f"  {col1} == {col2}: {corr:.3f} ({direction})")
else:
    print("  Сильные корреляции отсутствуют")

# Корреляции с целевой переменной (mpg)
print("Корреляция с mpg")
mpg_corr = corr_matrix['mpg'].sort_values(ascending=False)
for feature, corr_value in mpg_corr.items():
    if feature != 'mpg' and abs(corr_value) > 0.3:
        direction = "положительная" if corr_value > 0 else "отрицательная"
        print(f"  {feature}: {corr_value:.3f} ({direction})")

# Прямой график рассеивания
# Выберем наиболее коррелированные с mpg признаки
top_features = mpg_corr.abs().sort_values(ascending=False).index[1:5]  # исключаем mpg
print(f"Анализируемые признаки: {list(top_features)}")

# Создаем копию данных и обрабатываем пропуски
analysis_df = df[list(top_features) + ['mpg']].copy()

# Заполняем пропуски в horsepower медианным значением
if 'horsepower' in analysis_df.columns and analysis_df['horsepower'].isnull().any():
    horsepower_median = analysis_df['horsepower'].median()
    analysis_df['horsepower'] = analysis_df['horsepower'].fillna(horsepower_median)
    print(f"Заполнено {df['horsepower'].isnull().sum()} пропусков в horsepower медианой: {horsepower_median}")

# Упрощенная матрица scatter plot
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.ravel()

for i, feature in enumerate(top_features):
    # Проверяем, что в данных нет пропусков
    if analysis_df[feature].isnull().any():
        print(f"Предупреждение: в признаке {feature} все еще есть пропуски")
        continue

    sns.scatterplot(data=analysis_df, x=feature, y='mpg', ax=axes[i], alpha=0.7)
    axes[i].set_title(f'mpg vs {feature}', fontweight='bold')

    # Добавляем линию тренда
    try:
        z = np.polyfit(analysis_df[feature], analysis_df['mpg'], 1)
        p = np.poly1d(z)
        axes[i].plot(analysis_df[feature], p(analysis_df[feature]), "r--", alpha=0.8,
                    label=f'тренд: y={z[0]:.3f}x+{z[1]:.3f}')
        axes[i].legend()
    except Exception as e:
        print(f"Ошибка при построении тренда для {feature}: {e}")

plt.tight_layout()
plt.show()

# Парные графики ключевых признаков
key_features = ['mpg', 'weight', 'horsepower', 'displacement', 'acceleration']
sns.pairplot(df[key_features], diag_kind='kde', plot_kws={'alpha': 0.6})
plt.suptitle('Парные зависимости ключевых признаков', y=1.02)
plt.show()

# Проанализирован датасет Auto MPG (398 автомобилей, 9 признаков).
# Обнаружены пропуски в horsepower и выбросы в нескольких признаках.
# Выявлены сильные корреляции: расход топлива (mpg) сильно зависит от веса и мощности
# (отрицательная связь), а также взаимосвязи между техническими характеристиками.